{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e9090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import string\n",
    "import sys\n",
    "import warnings\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "from urllib.error import URLError\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import json\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "#from .utils import download_and_extract_archive, extract_archive, verify_str_arg, check_integrity\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "class BIWI(VisionDataset):\n",
    "\n",
    "\n",
    "    training_file = \"training.pt\"\n",
    "    test_file = \"test.pt\"\n",
    "\n",
    "\n",
    "    @property\n",
    "    def train_labels(self):\n",
    "        warnings.warn(\"train_labels has been renamed targets\")\n",
    "        return self.targets\n",
    "\n",
    "    @property\n",
    "    def test_labels(self):\n",
    "        warnings.warn(\"test_labels has been renamed targets\")\n",
    "        return self.targets\n",
    "\n",
    "    @property\n",
    "    def train_data(self):\n",
    "        warnings.warn(\"train_data has been renamed data\")\n",
    "        return self.data\n",
    "\n",
    "    @property\n",
    "    def test_data(self):\n",
    "        warnings.warn(\"test_data has been renamed data\")\n",
    "        return self.data\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str = None,\n",
    "        train: bool = True,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        split : float = 1\n",
    "      \n",
    "    ) -> None:\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "        self.train = train  # training set or test set\n",
    "        self.split = split\n",
    "        self.height=96\n",
    "        self.width=96\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\t\n",
    "        self.json_files = self._load_data()\n",
    " \n",
    "        \n",
    "\n",
    "        \n",
    "    def _load_data(self,mypath = \"/home/nandhini/Animals\"):\n",
    "        onlyfiles_json = []\n",
    "        \n",
    "        for data in glob.glob(mypath+\"/*.json\"):\n",
    "            onlyfiles_json.append(data)\n",
    "            \n",
    "        # calculate the validation data sample length\n",
    "        valid_split = int(len(onlyfiles_json) * self.split)\n",
    "        # calculate the training data samples length\n",
    "        train_split = int(len(onlyfiles_json) - valid_split)  \n",
    "        \n",
    "        if self.train == True:\n",
    "            onlyfiles_json = onlyfiles_json[:train_split]\n",
    "            print(f\"Training sample instances: {len(onlyfiles_json)}\")\n",
    "        elif self.train == False:\n",
    "            onlyfiles_json = onlyfiles_json[-valid_split:]\n",
    "            print(f\"Validation sample instances: {len(onlyfiles_json)}\")\n",
    "        \n",
    "        return onlyfiles_json\n",
    "       \n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        \n",
    "        data = json.load(open(self.json_files[index]))\n",
    "        img_path = self.json_files[index].split('.')[0] + '.jpeg'\n",
    "        target = data[\"shapes\"][0][\"points\"][0]\n",
    "        \n",
    "\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        res_x, res_y = img.size\n",
    "        img = img.resize((self.height,self.width), Image.ANTIALIAS)\n",
    "        convert = ToTensor()\n",
    "        img = convert(img)\n",
    "\n",
    "\n",
    "        target = [target[0]/res_x, target[1]/res_y]\n",
    "\n",
    "\n",
    "        target = torch.Tensor(target)\n",
    "        \n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "            \n",
    "\n",
    "       \n",
    "        return img, target\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.json_files)\n",
    "    \n",
    "    @property\n",
    "    def raw_folder(self) -> str:\n",
    "        return os.path.join(self.root, self.__class__.__name__, \"raw\")\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self) -> str:\n",
    "        return os.path.join(self.root, self.__class__.__name__, \"processed\")\n",
    "\n",
    "    @property\n",
    "    def class_to_idx(self) -> Dict[str, int]:\n",
    "        return {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "    def _check_exists(self) -> bool:\n",
    "        return all(\n",
    "            check_integrity(os.path.join(self.raw_folder, os.path.splitext(os.path.basename(url))[0]))\n",
    "            for url, _ in self.resources\n",
    "        )\n",
    "\n",
    "    def download(self) -> None:\n",
    "        \"\"\"Download the MNIST data if it doesn't exist already.\"\"\"\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        os.makedirs(self.raw_folder, exist_ok=True)\n",
    "\n",
    "        # download files\n",
    "        for filename, md5 in self.resources:\n",
    "            for mirror in self.mirrors:\n",
    "                url = f\"{mirror}{filename}\"\n",
    "                try:\n",
    "                    print(f\"Downloading {url}\")\n",
    "                    download_and_extract_archive(url, download_root=self.raw_folder, filename=filename, md5=md5)\n",
    "                except URLError as error:\n",
    "                    print(f\"Failed to download (trying next):\\n{error}\")\n",
    "                    continue\n",
    "                finally:\n",
    "                    print()\n",
    "                break\n",
    "            else:\n",
    "                raise RuntimeError(f\"Error downloading {filename}\")\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        split = \"Train\" if self.train is True else \"Test\"\n",
    "        return f\"Split: {split}\"\n",
    "\n",
    "    # get the training and validation data samples\n",
    "print('\\n-------------- PREPARING DATA --------------\\n')\n",
    "train_data=BIWI(train = True)\n",
    "valid_data = BIWI(train = False)\n",
    "\n",
    "print('\\n-------------- DATA PREPRATION DONE --------------\\n')\n",
    "   \n",
    "    # prepare data loaders\n",
    "train_loader = DataLoader(train_data,\n",
    "                              batch_size=256,\n",
    "                              shuffle=False)\n",
    "valid_loader = DataLoader(valid_data,\n",
    "                              batch_size=256,\n",
    "                              shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
